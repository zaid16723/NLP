import nltk
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag
from nltk.corpus import stopwords
text = "John likes to play football with his friends."
tokens = word_tokenize(text)
def rule_based_pos_tagging(tokens):
 tagged_tokens = []
 for token in tokens:
 if token.lower() in ["john", "he", "his"]:
 tagged_tokens.append((token, 'NNP')) # Proper noun
 elif token.lower() in ["likes", "play"]:
 tagged_tokens.append((token, 'VB'))
 elif token.lower() in ["to", "with"]:
 tagged_tokens.append((token, 'TO')) # To or preposition
 elif token.lower() in ["football", "friends"]:
 tagged_tokens.append((token, 'NN')) # Noun
 else:
 tagged_tokens.append((token, 'NN')) # Default to noun
 return tagged_tokens
def statistical_pos_tagging(tokens):
 tagged_tokens = pos_tag(tokens)
 return tagged_tokens
stop_words = set(stopwords.words('english'))
tokens_without_stopwords = [token for token in tokens if token.lower() not in stop_words]
rule_based_tags = rule_based_pos_tagging(tokens)
statistical_tags = statistical_pos_tagging(tokens_without_stopwords)
print("Rule-based PoS tagging:")
print(rule_based_tags)
print("\nStatistical PoS tagging:")
print(statistical_tags)
